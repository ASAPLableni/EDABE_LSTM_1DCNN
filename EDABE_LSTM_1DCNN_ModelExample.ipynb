{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8cdaea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:25:40.103622Z",
     "start_time": "2023-01-25T20:25:39.767248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Input, GRU\n",
    "from keras.layers import BatchNormalization, Lambda, Add, concatenate, Reshape\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau,TensorBoard\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b511e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fecc9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:24:42.248722Z",
     "start_time": "2023-01-25T20:24:42.222792Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_recognition(neurons, window, dropout_value = 0.05):\n",
    "    \n",
    "    filter_size = 32 \n",
    "    kernel_size = 5\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputs = Input((window, 1))\n",
    "    \n",
    "    lstm1 = LSTM(16, activation=\"tanh\", return_sequences=True)(inputs)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    lstm1 = Dropout(dropout_value)(lstm1)\n",
    "\n",
    "    lstm2 = LSTM(16, activation=\"tanh\", return_sequences=True)(lstm1)\n",
    "    lstm2 = BatchNormalization()(lstm2)\n",
    "    lstm2 = Dropout(dropout_value)(lstm2)\n",
    "\n",
    "    conv1 = Conv1D(filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(lstm2)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1_1 = Conv1D(filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv1D(filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    #conv1_1 = Conv1D(64, 1, activation='relu')(conv1\n",
    "    drop1 = Dropout(dropout_value)(conv1_2)\n",
    "    add1 = Add()([drop1, conv1])\n",
    "    max1 = MaxPooling1D(pool_size=2)(add1)\n",
    "    \n",
    "    conv2 = Conv1D(2*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(max1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2_1 = Conv1D(2*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv1D(2*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    #conv2_2 = Conv1D(64, 1, activation='relu')(conv2)\n",
    "    drop2 = Dropout(dropout_value)(conv2_2)\n",
    "    add1 = Add()([drop2, conv2])\n",
    "    max2 = MaxPooling1D(pool_size=2)(add1)\n",
    "    \n",
    "    conv0 = Conv1D(4*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(max2)\n",
    "    conv0 = BatchNormalization()(conv0)\n",
    "    conv0_1 = Conv1D(4*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv0)\n",
    "    conv0_1 = BatchNormalization()(conv0_1)\n",
    "    conv0_2 = Conv1D(4*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv0_1)\n",
    "    conv0_2 = BatchNormalization()(conv0_2)\n",
    "    #conv2_2 = Conv1D(64, 1, activation='relu')(conv2)\n",
    "    drop0 = Dropout(dropout_value)(conv0_2)\n",
    "    add0 = Add()([drop0, conv0])\n",
    "    max0 = MaxPooling1D(pool_size=2)(add0)\n",
    "\n",
    "    conv3 = Conv1D(8*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(max0)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3_1 = Conv1D(8*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv1D(8*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    #conv2_2 = Conv1D(64, 1, activation='relu')(conv2)\n",
    "    drop3 = Dropout(dropout_value)(conv3_2)\n",
    "    add3 = Add()([drop3, conv3])\n",
    "    max3 = MaxPooling1D(pool_size=2)(add3)\n",
    "\n",
    "    conv4 = Conv1D(16*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(max3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4_1 = Conv1D(16*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv1D(16*filter_size, kernel_size, activation='relu', padding = 'same',\n",
    "                   kernel_initializer = 'he_normal')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    #conv2_2 = Conv1D(64, 1, activation='relu')(conv2)\n",
    "    drop4 = Dropout( dropout_value )(conv4_2)\n",
    "    add4 = Add()([drop4, conv4])\n",
    "    max4 = MaxPooling1D(pool_size=2)(add4)\n",
    "    \n",
    "    # lstm3 = LSTM(128, activation=\"tanh\")(max4)\n",
    "    # lstm3 = BatchNormalization()(lstm3)\n",
    "    # lstm3 = Dropout(dropout_value)(lstm3)\n",
    "  \n",
    "    # lstm1 = GRU(128, activation=\"tanh\")(max4)\n",
    "    \n",
    "    # dense1 = Dense(512, activation = \"relu\")(lstm3)\n",
    "    # dense1 = BatchNormalization()(dense1)\n",
    "    # dense1 = Dropout(0.5)(dense1)\n",
    "        \n",
    "    flat = Flatten()(max4)\n",
    "\n",
    "    dense6 = Dense(256, activation = \"relu\")(flat)\n",
    "    dense6 = BatchNormalization()(dense6)\n",
    "    dense6 = Dropout(0.5)(dense6)\n",
    "    \n",
    "    dense8 = Dense(16, activation=\"relu\")(dense6)\n",
    "    dense8 = BatchNormalization()(dense8)\n",
    "    dense8 = Dropout(0.5)(dense8)\n",
    "    \n",
    "    dense7 = Dense(1, activation=\"sigmoid\")(dense8) \n",
    "    \n",
    "    model = Model(inputs, dense7)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee405a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:24:44.270228Z",
     "start_time": "2023-01-25T20:24:42.571042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Desktop\\LabLENI\\DescriptionEDA\\Code\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_signal_LSTM = model_recognition(neurons=128, window=5*128, dropout_value=0.05)\n",
    "\n",
    "### Loading the weights of the DL model.\n",
    "# x = load_model(\"models/new_clean_raw_signal.h5\")\n",
    "raw_signal_LSTM.load_weights(\"Model/EDABE_LSTM_1DCNN_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488e71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c7c4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:25:56.931183Z",
     "start_time": "2023-01-25T20:25:56.473767Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ex = pd.read_csv(\"Data/Corrected_oxused_expert2.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed5d44f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:33:26.471586Z",
     "start_time": "2023-01-25T20:33:26.450567Z"
    }
   },
   "outputs": [],
   "source": [
    "def charge_raw_data(df, x_col=\"rawdata\", target_size_frames=64, y_col=None, freq_signal=128, verbose=False):\n",
    "    \n",
    "    x_signal = df[x_col].values\n",
    "    if y_col is not None:\n",
    "        y_signal = df[y_col].values\n",
    "    \n",
    "    window_size = 5 * freq_signal\n",
    "\n",
    "    x_window_list, y_window_list = [], []\n",
    "    \n",
    "    i = 0\n",
    "    while i <= len(x_signal)-window_size:\n",
    "        \n",
    "        denominator_norm = (np.nanmax(x_signal[i:(i+window_size)])-np.nanmin(x_signal[i:(i+window_size)]))\n",
    "        \n",
    "        x_signal_norm = (x_signal[i:(i+window_size)]-np.nanmin(x_signal[i:(i+window_size)]))/denominator_norm\n",
    "        x_window_list.append( x_signal_norm )\n",
    "        \n",
    "        if y_col is not None:\n",
    "            cond = np.nanmean( y_signal[(i+window_size-target_size_frames):(i+window_size)] ) > 0.5\n",
    "            y_window_list.append( 1 if cond else 0)\n",
    "\n",
    "        if i % 50000 == 0 and verbose:\n",
    "            print(\"Iteration\", i, \"of\", len(x_signal)-window_size-1, end=\"\\r\")\n",
    "        \n",
    "        i += target_size_frames\n",
    "    \n",
    "    return np.array(x_window_list), np.array(y_window_list)\n",
    "\n",
    "\n",
    "def find_begin_end( x_p ):\n",
    "    \n",
    "    pos_artf_true = which_element( x_p == 1 )\n",
    "\n",
    "    start_pos_artf_true = [ pos_artf_true[0] ]\n",
    "    for i, p_art_t in enumerate( pos_artf_true[1:] ):\n",
    "        if p_art_t-pos_artf_true[i] > 1:\n",
    "            start_pos_artf_true.append( p_art_t )\n",
    "\n",
    "    end_pos_artf_true = [\n",
    "        p_art_t for i, p_art_t in enumerate( pos_artf_true[:-1] ) if pos_artf_true[i+1]-p_art_t > 1\n",
    "    ]\n",
    "\n",
    "    end_pos_artf_true.append( pos_artf_true[-1] )\n",
    "    \n",
    "    return start_pos_artf_true, end_pos_artf_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd4198d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-25T20:37:52.140270Z",
     "start_time": "2023-01-25T20:37:52.124254Z"
    }
   },
   "outputs": [],
   "source": [
    "def automatic_EDA_correct( df, model, \n",
    "                          freq_signal=128, th_t_postprocess=2.5, \n",
    "                          eda_signal=\"uS\", time_column=\"UnixTimestamp\"):\n",
    "\n",
    "    target_size_frames = 64\n",
    "\n",
    "    df[eda_signal][df[eda_signal] < 0] = 0\n",
    "    \n",
    "    df[\"signal_automatic\"] = df[eda_signal].iloc[:]\n",
    "    rawdata_spline_correct = df[eda_signal].iloc[:]\n",
    "\n",
    "    x, _ = charge_raw_data( df, x_col=eda_signal, target_size_frames=target_size_frames)\n",
    "    \n",
    "    x_res = np.resize(x, (x.shape[0], x.shape[1], 1))\n",
    "    \n",
    "    #############################\n",
    "    ### AUTOMATIC RECOGNITION ###\n",
    "    #############################\n",
    "    with tf.device('/cpu:0'):\n",
    "        y_pred = model.predict(x_res, verbose=1)\n",
    "    \n",
    "    y_pred[y_pred <= 0.2] = 0\n",
    "    y_pred[y_pred > 0.2] = 1\n",
    "    \n",
    "    y_pred[np.isnan(y_pred)] = 0\n",
    "    \n",
    "    future_labels_auto = np.zeros( df.shape[0] )\n",
    "\n",
    "    counter_label = 0\n",
    "    for label in y_pred[:,0]:\n",
    "        future_labels_auto[ target_size_frames*counter_label:target_size_frames*(counter_label+1) ] += label\n",
    "        counter_label += 1\n",
    "    \n",
    "    #######################\n",
    "    ### POST-PROCESSING ###\n",
    "    #######################\n",
    "\n",
    "    pred_target_array = df[eda_signal].iloc[:].copy()\n",
    "    \n",
    "    future_labels_auto[future_labels_auto > 0] = 1\n",
    "    pred_target_array = future_labels_auto\n",
    "\n",
    "    df[\"PredArtifacts\"] = pred_target_array\n",
    "\n",
    "    start_artf_pred, end_artf_pred = find_begin_end( pred_target_array )\n",
    "    # print( \"Number of artefacts predicted without post-processed\", len(start_artf_pred) )\n",
    "    \n",
    "    for i in range( len(start_artf_pred)-1 ):\n",
    "        if np.abs(start_artf_pred[i+1] - end_artf_pred[i])/freq_signal <= th_t_postprocess:\n",
    "            pred_target_array[ end_artf_pred[i]:start_artf_pred[i+1] ] = 1\n",
    "    \n",
    "    start_artf_pred, end_artf_pred = find_begin_end( pred_target_array )\n",
    "    \n",
    "    df[\"PostProcessedPredArtifacts\"] = pred_target_array\n",
    "\n",
    "    dict_metrics = {}\n",
    "\n",
    "    dict_metrics[\"time_first_artifact\"] = start_artf_pred[0]/freq_signal\n",
    "\n",
    "    t_btw_artf = ( np.array(start_artf_pred)[1:]-np.array(end_artf_pred)[:-1] )/freq_signal\n",
    "    dict_metrics[\"time_between_artifact\"] = np.mean(t_btw_artf)\n",
    "\n",
    "    dur_time_artf_subj_train = (np.array(end_artf_pred)-np.array(start_artf_pred))/freq_signal\n",
    "    dict_metrics[\"mean_artifact_duration\"] = np.mean(dur_time_artf_subj_train)\n",
    "\n",
    "    dict_metrics[\"minimum_artifact_duration\"] = np.min(dur_time_artf_subj_train)\n",
    "\n",
    "    perc_of_artf = 100 * np.sum( pred_target_array )/df.shape[0]\n",
    "    dict_metrics[\"percentage_of_artifacts\"] = perc_of_artf\n",
    "\n",
    "    n_artf_obtain = len(start_artf_pred)\n",
    "    dict_metrics[\"number_of_artifacts\"] = n_artf_obtain\n",
    "\n",
    "    # print( \"Number of artefacts predicted post-processed\", n_artf_obtain )\n",
    "    \n",
    "    # print(\"Beginning of the interpolation\")\n",
    "    \n",
    "    ############################\n",
    "    ### AUTOMATIC CORRECTION ### \n",
    "    ############################\n",
    "    \n",
    "    start_artf, end_artf = find_begin_end( pred_target_array )\n",
    "    \n",
    "    begin_bad_elements = start_artf\n",
    "    end_bad_elements= end_artf\n",
    "    \n",
    "    for ctr_it in range( len(end_bad_elements) ):        \n",
    "        \n",
    "        begin_index = begin_bad_elements[ctr_it]-int(freq_signal/4)\n",
    "            \n",
    "        if begin_index < 0:\n",
    "            begin_index = 0\n",
    "            \n",
    "        end_index = end_bad_elements[ctr_it]+int(freq_signal/4)\n",
    "                      \n",
    "        to_clean_segment = df[time_column].iloc[begin_index:end_index]\n",
    "        \n",
    "        to_plot = to_clean_segment\n",
    "        to_clean = df[eda_signal].iloc[to_clean_segment.index.values]\n",
    "        \n",
    "        th_init_space = 0 if begin_bad_elements[ctr_it] == 0 else int(freq_signal/4)-1\n",
    "        \n",
    "        th_end_space = int(freq_signal/4)\n",
    "        \n",
    "        initl_pnt = to_clean.iloc[th_init_space]\n",
    "        final_pnt = to_clean.iloc[-th_end_space]\n",
    "\n",
    "        x_all_int = to_clean.index.values\n",
    "        x_int = to_clean[th_init_space:-th_end_space].index.values\n",
    "        y_int = to_clean[th_init_space:-th_end_space].values\n",
    "        \n",
    "        #########################\n",
    "        ### SPLINE CORRECTION ###\n",
    "        #########################\n",
    "\n",
    "        f = interp1d([x_int[0], x_int[-1]], [y_int[0], y_int[-1]], kind=\"linear\")\n",
    "        \n",
    "        intermediam_correct_lineal = f(x_int)\n",
    "        init_correct = to_clean.iloc[:th_init_space] \n",
    "        final_correct = to_clean.iloc[-th_end_space:]\n",
    "            \n",
    "        x_to_spline = [x_int[0]]+down_sample(x_int, f = x_int.shape[0]/8)+[x_int[-1]]\n",
    "        y_to_spline = [y_int[0]]+down_sample(y_int, f = y_int.shape[0]/8)+[y_int[-1]]\n",
    "            \n",
    "        y_output = sc_int.spline( x_to_spline, y_to_spline, x_int )\n",
    "\n",
    "        mix_curve = np.mean([intermediam_correct_lineal, y_output], axis=0)\n",
    "        \n",
    "        tuple_concat = (mix_curve, final_correct) if init_correct.shape[0] < 2 else (init_correct, mix_curve, final_correct)\n",
    "        correct_linear = np.concatenate(tuple_concat, axis=0)\n",
    "        \n",
    "        df[\"signal_automatic\"].iloc[to_clean_segment.index.values] = moving_average(correct_linear, freq_signal/8 )\n",
    "\n",
    "    return df, dict_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da27a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395df031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0977c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
